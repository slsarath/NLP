Awesome! Here‚Äôs your ready-to-run app.py Streamlit web app that:

‚úÖ Connects to your Databricks SQL Warehouse
‚úÖ Uses your Databricks API Token securely
‚úÖ Queries a sample table (incident_logs)
‚úÖ Shows a summary dashboard
‚úÖ Integrates GPT-4o via Azure OpenAI API
‚úÖ Supports Q&A and Control Suggestion

‚∏ª

üßæ Step-by-Step Setup (Before Running)

üîπ 1. Install Required Packages

pip install streamlit databricks-sdk openai python-dotenv pandas

üîπ 2. Create .env File (Store Credentials Securely)

Create a file named .env in the same folder with the following content:

# Databricks credentials
DATABRICKS_HOST=https://adb-1234567890123456.8.azuredatabricks.net
DATABRICKS_HTTP_PATH=/sql/1.0/warehouses/<your-warehouse-id>
DATABRICKS_TOKEN=dapiXXXXXXXXXXXXXXXXXXXXXXXX

# Azure OpenAI
AZURE_OPENAI_ENDPOINT=https://<your-openai-endpoint>.openai.azure.com/
AZURE_OPENAI_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
AZURE_OPENAI_DEPLOYMENT=gpt-4o

Replace placeholders (<...>) with your actual values.

‚∏ª

‚úÖ Now: app.py ‚Äì Full Streamlit Web App

import streamlit as st
import pandas as pd
from databricks import sql
from dotenv import load_dotenv
import os
import openai

# --- Load environment variables ---
load_dotenv()
db_host = os.getenv("DATABRICKS_HOST")
http_path = os.getenv("DATABRICKS_HTTP_PATH")
db_token = os.getenv("DATABRICKS_TOKEN")

openai.api_type = "azure"
openai.api_base = os.getenv("AZURE_OPENAI_ENDPOINT")
openai.api_key = os.getenv("AZURE_OPENAI_KEY")
openai.api_version = "2023-07-01-preview"  # Update if needed
openai_deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT")

# --- Page setup ---
st.set_page_config(page_title="AI Risk Control Assistant", layout="wide")
st.title("üîê AI-Powered Risk & Control Assistant")

# --- Databricks Connection ---
@st.cache_resource
def get_data():
    with sql.connect(server_hostname=db_host, http_path=http_path, access_token=db_token) as connection:
        cursor = connection.cursor()
        cursor.execute("SELECT * FROM catalog.schema.incident_logs LIMIT 100")
        rows = cursor.fetchall()
        columns = [desc[0] for desc in cursor.description]
        df = pd.DataFrame(rows, columns=columns)
        return df

df = get_data()
st.subheader("üìä Incident Summary")
st.dataframe(df)

# --- Visual Summary ---
st.bar_chart(df['incident_type'].value_counts())
st.line_chart(df.groupby('detected_date').size())

# --- GPT-Powered Risk Q&A ---
st.subheader("ü§ñ Ask a Question About Incidents")

user_question = st.text_input("What would you like to know?", placeholder="e.g., Which department had most unresolved incidents?")
if user_question:
    response = openai.ChatCompletion.create(
        engine=openai_deployment,
        messages=[
            {"role": "system", "content": "You are a risk control analyst. Answer based on incident logs."},
            {"role": "user", "content": f"Question: {user_question}. Data:\n{df.head(10).to_json()}"},
        ],
        temperature=0.5,
        max_tokens=500
    )
    st.markdown(f"**Answer:** {response['choices'][0]['message']['content']}")

# --- GPT: Suggest Control Improvements ---
st.subheader("üõ†Ô∏è Suggest Improvements to Controls")

sample_incident = st.text_area("Paste an incident description:", placeholder="AML breach due to irregular fund flow...")
if sample_incident:
    suggestion = openai.ChatCompletion.create(
        engine=openai_deployment,
        messages=[
            {"role": "system", "content": "You are a compliance advisor. Suggest control improvements for given risk incident."},
            {"role": "user", "content": f"Incident: {sample_incident}"}
        ],
        temperature=0.4,
        max_tokens=300
    )
    st.success(suggestion['choices'][0]['message']['content'])

# --- Footer ---
st.caption("Built using Azure Databricks + Azure OpenAI + Streamlit")


‚∏ª

‚úÖ To Run the App:

streamlit run app.py


‚∏ª

üß† Future Extensions You Can Add
	‚Ä¢	Word Cloud of frequent risk terms
	‚Ä¢	Incident severity trend
	‚Ä¢	Filter by department, reporter, or risk score
	‚Ä¢	Upload button for new CSVs
	‚Ä¢	Save GPT suggestions to a Delta table

‚∏ª

Would you like me to:
	‚Ä¢	Add topic modeling with LDA?
	‚Ä¢	Show root cause classification with GPT?
	‚Ä¢	Or auto-flag controls using regex or embedding comparison?

Let me know how you want to extend this!