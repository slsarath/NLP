Got it — I’ll make it so that instead of only showing the base keyword, it also shows the exact variation found in the cell.

That way, if someone wrote crossborder or Cross-Border, you’ll know exactly what was typed in the source, not just the cleaned base keyword.

Here’s the updated script:

⸻


import pandas as pd
import re

# -------- CONFIG --------
input_excel = "input.xlsx"             # Your main data file
keywords_file = "keywords.txt"         # Base keywords, one per line
output_excel = "output_with_matches.xlsx"

text_columns = [
    "Issue Title",
    "Issue Description",
    "Issue Impact",
    "Issue Root cause",
    "Issue Progress Update",
    "Related Standard(s)",
    "Related Risks",
    "Related Control ID - Name",
    "Control(s) mapped to selected PRO(s)"
]

# -------- STEP 1: LOAD DATA --------
df = pd.read_excel(input_excel)

# -------- STEP 2: LOAD BASE KEYWORDS --------
with open(keywords_file, "r", encoding="utf-8") as f:
    base_keywords = [line.strip() for line in f if line.strip()]

# -------- STEP 3: TEXT NORMALIZATION --------
def normalize_text(text):
    if pd.isna(text):
        return ""
    text = str(text).lower()
    text = re.sub(r"[^a-z0-9\s]", " ", text)   # remove special chars
    text = re.sub(r"\s+", " ", text).strip()
    return text

# -------- STEP 4: GENERATE VARIATIONS --------
def generate_variations(keyword):
    norm_kw = normalize_text(keyword)
    variations = {norm_kw}
    variations.add(norm_kw.replace(" ", "-"))
    variations.add(norm_kw.replace(" ", ""))
    if "licence" in norm_kw:
        variations.add(norm_kw.replace("licence", "license"))
    if "license" in norm_kw:
        variations.add(norm_kw.replace("license", "licence"))
    return variations

# -------- STEP 5: BUILD PATTERNS --------
patterns = []
for base_kw in base_keywords:
    for variant in generate_variations(base_kw):
        kw_regex = r"\b" + re.escape(variant) + r"\b"
        patterns.append((base_kw, variant, re.compile(kw_regex, flags=re.IGNORECASE)))

# -------- STEP 6: EXTRACT MATCHES PER ROW --------
def extract_keywords_regex(row):
    found = []
    for col in text_columns:
        col_val = str(row.get(col, ""))
        normalized_col_val = normalize_text(col_val)
        matches = [
            f"{base_kw} → '{m.group(0)}'"
            for base_kw, variant, pat in patterns
            for m in pat.finditer(normalized_col_val)
        ]
        if matches:
            found.append(f"{col}: {', '.join(sorted(set(matches)))}")
    return "; ".join(found) if found else None

df["extracted text"] = df.apply(extract_keywords_regex, axis=1)

# -------- STEP 7: FILTER MATCHED ROWS --------
df_matches = df[df["extracted text"].notna()]

# -------- STEP 8: SAVE TO EXCEL --------
with pd.ExcelWriter(output_excel) as writer:
    df.to_excel(writer, index=False, sheet_name="Full Data")
    df_matches.to_excel(writer, index=False, sheet_name="Matched Rows")

print(f"✅ Done! Results saved to {output_excel}")


⸻

Example Output for extracted text Column

Issue Description: Cross Border → 'crossborder', Licensing → 'licencing'
Issue Impact: Reach in → 'reach in'

This makes it crystal clear:
	•	Left side = base keyword from your config file
	•	Right side (in quotes) = exact text found in that cell

⸻

If you want, I can also make it highlight matches in the Excel output so they’re visually easy to spot.
Do you want me to add that?