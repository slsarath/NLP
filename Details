import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from keybert import KeyBERT

# Step 1: Setup
nltk.download('stopwords')
default_stopwords = set(stopwords.words('english'))
custom_stopwords = {"ess", "ffr"}
all_stopwords = default_stopwords.union(custom_stopwords)

def clean_text(text):
    text = re.sub(r'[^a-zA-Z\s]', ' ', str(text).lower())
    tokens = [word for word in text.split() if word not in all_stopwords]
    return " ".join(tokens)

# Step 2: Load your data
df = pd.read_csv("negative_transcripts.csv")  # <-- Replace with your file path

# Step 3: Filter Customer + Negative and group by Cust_id
filtered = df[
    (df['Participant_id'].str.lower() == 'customer') &
    (df['Sentiment'].str.lower() == 'negative')
].dropna(subset=['Transcript'])

filtered['Cleaned'] = filtered['Transcript'].apply(clean_text)

# Step 4: Aggregate negative text per Cust_id
grouped = filtered.groupby('Cust_id')['Cleaned'].apply(lambda x: ' '.join(x)).reset_index()
grouped = grouped[grouped['Cleaned'].str.strip() != ""].reset_index(drop=True)

# Step 5: TF-IDF theme extraction per Cust_id
vectorizer = TfidfVectorizer(stop_words=list(all_stopwords), ngram_range=(2, 4), min_df=1)
tfidf_matrix = vectorizer.fit_transform(grouped['Cleaned'])
feature_names = vectorizer.get_feature_names_out()

def get_top_tfidf_phrases(tfidf_row, top_n=2):
    row = tfidf_row.toarray().flatten()
    top_idx = row.argsort()[::-1][:top_n]
    return ", ".join([feature_names[i] for i in top_idx])

grouped['TFIDF_Themes'] = [
    get_top_tfidf_phrases(tfidf_matrix[i], top_n=2)
    for i in range(tfidf_matrix.shape[0])
]

# Step 6: KeyBERT theme extraction per Cust_id
kw_model = KeyBERT(model='all-MiniLM-L6-v2')
grouped['KeyBERT_Themes'] = grouped['Cleaned'].apply(
    lambda x: ", ".join([kw[0] for kw in kw_model.extract_keywords(x, keyphrase_ngram_range=(2, 4), stop_words=list(all_stopwords), top_n=2)])
)

# Step 7: Map themes back to original DataFrame
theme_map_tfidf = dict(zip(grouped['Cust_id'], grouped['TFIDF_Themes']))
theme_map_kbert = dict(zip(grouped['Cust_id'], grouped['KeyBERT_Themes']))

df['TFIDF_Themes'] = df['Cust_id'].map(theme_map_tfidf)
df['KeyBERT_Themes'] = df['Cust_id'].map(theme_map_kbert)

# Step 8: Done! Preview
print(df[['Cust_id', 'Transcript', 'TFIDF_Themes', 'KeyBERT_Themes']].head(10))

# Optional: Save output
# df.to_csv("with_theme_phrases.csv", index=False)