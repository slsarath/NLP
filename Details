from sentence_transformers import util

def semantic_search_with_keywords(text, phrase_embeddings, phrases_list, theme_dict, top_k=5, min_similarity=0.3, boost_factor=0.2):
    # Encode the input text
    text_embedding = model_mpnet.encode(text, convert_to_tensor=True)
    similarity_scores = []
    
    # Split text into words for keyword matching
    text_words = set(text.lower().split())
    
    # Iterate over phrases to calculate similarity and check keyword matches
    for i, phrase in enumerate(phrases_list):
        phrase_words = set(phrase.lower().split())
        
        # Check for keyword match
        keyword_match = any(word in text_words for word in phrase_words)
        
        # Calculate semantic similarity score
        phrase_embedding = phrase_embeddings[i]
        semantic_similarity = util.pytorch_cos_sim(text_embedding, phrase_embedding).item()
        
        # Boost score if keyword match exists
        boosted_score = semantic_similarity + (boost_factor if keyword_match else 0.0)
        
        # Store score along with theme info
        similarity_scores.append((i, boosted_score))
    
    # Sort phrases by their boosted similarity scores
    top_indices = sorted(similarity_scores, key=lambda x: x[1], reverse=True)
    
    # Prepare the top phrases by theme, ensuring each theme appears only once
    top_phrases = []
    seen_themes = set()
    
    for idx, score in top_indices:
        if len(top_phrases) >= top_k:
            break
        phrase = phrases_list[idx]
        theme = theme_dict.get(phrase, None)
        
        # Limit the results per theme for variety
        if theme not in seen_themes:
            top_phrases.append((phrase, score))
            seen_themes.add(theme)
    
    return top_phrases if top_phrases else similarity_scores[:top_k]