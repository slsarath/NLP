import pandas as pd
from sentence_transformers import SentenceTransformer, util
import re

# Load the sentence transformer model for semantic matching
model = SentenceTransformer('all-MiniLM-L6-v2')

# Define keywords for each aspect
criteria_keywords = {
    "Source of Funds": [r"source of funds[:\-]", r"sow[:\-]", r"sow summary[:\-]"],
    "Purpose of Funds": [r"purpose of these funds[:\-]", r"purpose[:\-]"],
    "Where the Funds Have Come From": [r"where the funds have come from[:\-]", r"origin[:\-]"],
    "Rationale": [r"rationale[:\-]"]
}

# Define semantic fallback questions for each aspect
semantic_questions = {
    "Source of Funds": "What is the source of funds?",
    "Purpose of Funds": "What is the purpose of these funds?",
    "Where the Funds Have Come From": "Where have the funds come from?",
    "Rationale": "What is the rationale for this transaction?"
}

def extract_aspects(comment, criteria_keywords, semantic_questions, model):
    # Initialize a dictionary to store the extracted aspects
    extracted_data = {criterion: {"Matching Sentence": None, "Similarity Score": 0} for criterion in criteria_keywords}
    
    # Split the comment into sentences for semantic matching
    sentences = [sentence.strip() for sentence in comment.split('.') if sentence.strip()]
    
    try:
        for criterion, keywords in criteria_keywords.items():
            # First, try keyword-based extraction
            for keyword in keywords:
                match = re.search(keyword + r"(.+?)(?:\.|$)", comment, re.IGNORECASE)
                if match:
                    extracted_data[criterion]["Matching Sentence"] = match.group(1).strip()
                    extracted_data[criterion]["Similarity Score"] = 1.0  # Keyword match is exact
                    break
            
            # If no keyword-based match is found, use semantic matching
            if not extracted_data[criterion]["Matching Sentence"]:
                question_embedding = model.encode(semantic_questions[criterion], convert_to_tensor=True)
                max_similarity = 0
                matching_sentence = None

                for sentence in sentences:
                    sentence_embedding = model.encode(sentence, convert_to_tensor=True)
                    similarity = util.pytorch_cos_sim(question_embedding, sentence_embedding).item()
                    
                    if similarity > max_similarity:
                        max_similarity = similarity
                        matching_sentence = sentence
                
                # Store the best semantic match
                extracted_data[criterion]["Matching Sentence"] = matching_sentence
                extracted_data[criterion]["Similarity Score"] = max_similarity

    except Exception as e:
        print(f"Error during extraction: {e}")
    
    return extracted_data

# Sample DataFrame
data = {
    "comments": [
        """Source of funds: Cash held in USD account 00099. Where the funds have come from: Internal transfer from Wealth USD account into EDS account. Purpose of these funds: Transferred to NS&I for a better rate of interest. Rationale: We are comfortable with this transaction, funds originate from sale of Centessa shares which paid in USD into this account earlier this month.""",
        """SOW: Proceeds from house sale. Origin: Transferred from joint account. Purpose: Used for buying investments. Rationale: Funds cleared as per compliance.""",
        """Source: Monthly salary credited to account. Purpose of these funds: Savings for future investments."""
    ]
}

df = pd.DataFrame(data)

# Apply the extraction function to the DataFrame
results = df["comments"].apply(lambda x: extract_aspects(x, criteria_keywords, semantic_questions, model))

# Create new columns dynamically for each criterion
for criterion in criteria_keywords.keys():
    df[f"{criterion} Matching Sentence"] = results.apply(lambda x: x[criterion]["Matching Sentence"])
    df[f"{criterion} Similarity Score"] = results.apply(lambda x: x[criterion]["Similarity Score"])

# Display the DataFrame
df