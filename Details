import os
import pandas as pd
import re
from docx import Document

# Define the words/phrases list (both single words and multi-word phrases)
word_list = ["example", "test", "document", "trade union congress", "national party", "yed"]

# Convert the list to include both singular and plural forms (only for single words)
def generate_word_forms(word_list):
    word_forms = set()
    for word in word_list:
        if " " in word:  # Keep phrases as they are
            word_forms.add(word.lower())
        else:
            word_forms.add(rf'\b{word.lower()}\b')  # Use regex word boundary for exact match
            word_forms.add(rf'\b{word.lower()}s\b')  # Handle plural forms with word boundary
    return word_forms

word_forms = generate_word_forms(word_list)

# Function to preprocess text (remove unwanted characters)
def preprocess_text(text):
    # Convert to lowercase
    text = text.lower()
    # Remove special characters, keeping only alphanumeric and spaces
    text = re.sub(r'[^a-zA-Z0-9\s]', ' ', text)
    return text

# Function to search for keywords in the .docx file content
def search_in_docx(doc_file_path, word_forms):
    try:
        doc = Document(doc_file_path)
        full_text = []

        # Extract text from each paragraph in the document
        for para in doc.paragraphs:
            full_text.append(para.text)

        # Combine all text into a single string
        text = ' '.join(full_text)
        text = preprocess_text(text)

        found_words = set()
        extracts = []

        # Search for keywords/phrases in the text
        for phrase in word_forms:
            if " " in phrase:
                if phrase in text:
                    found_words.add(phrase)
                    # Extract relevant context around the found phrase
                    extracts.append(extract_context(text, phrase))
            else:
                matches = re.finditer(phrase, text)
                for match in matches:
                    found_words.add(phrase.strip(r'\b'))
                    # Extract relevant context around the found word
                    extracts.append(extract_context(text, match.group()))

        return list(found_words), extracts if found_words else [], []
    except Exception as e:
        print(f"Error processing {doc_file_path}: {e}")
        return [], []

# Function to extract context around the found keyword/phrase
def extract_context(text, phrase, window=30):
    try:
        start = max(text.find(phrase) - window, 0)
        end = min(text.find(phrase) + len(phrase) + window, len(text))
        return text[start:end]
    except Exception as e:
        print(f"Error extracting context: {e}")
        return ""

# Function to traverse directories and subdirectories and collect data
def traverse_and_search(root_folder, word_forms):
    data = []
    for root, dirs, files in os.walk(root_folder):
        for file in files:
            if file.endswith(".docx"):
                file_path = os.path.join(root, file)
                found_words, extracts = search_in_docx(file_path, word_forms)
                
                # Prepare the data to append to the DataFrame
                data.append({
                    "File Name": file,
                    "Found Words": found_words,
                    "Extracts": extracts
                })
    return data

# Path to the root folder containing .docx files
root_folder = '/path/to/your/folder'

# Traverse the folder and check for matching words, storing results in a list
data = traverse_and_search(root_folder, word_forms)

# Convert the list of results into a DataFrame
df = pd.DataFrame(data)

# Display the DataFrame
print(df)

# Optionally, save the DataFrame to a CSV file
df.to_csv("docx_search_results.csv", index=False)