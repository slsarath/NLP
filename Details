def semantic_search_mpnet(text, phrase_embeddings, phrases_list, theme_dict, top_k=5):
    words = text.split()
    if len(words) > 4:
        text_embedding = model.encode(text, convert_to_tensor=True)
        similarity_scores = [util.pytorch_cos_sim(text_embedding, phrase_emb).item() for phrase_emb in phrase_embeddings]

        top_indices = sorted(range(len(similarity_scores)), key=lambda i: similarity_scores[i], reverse=True)
        top_phrases = []
        seen_themes = set()

        for i in top_indices:
            if len(top_phrases) >= 3:
                break
            phrase = phrases_list[i]
            for theme, phrases in theme_dict.items():
                if phrase in phrases and theme not in seen_themes:
                    top_phrases.append((phrase, similarity_scores[i]))
                    seen_themes.add(theme)
                    break

        return top_phrases if top_phrases else []

    return []

# Example usage
text = "Your input text that is more than four words."
phrase_embeddings = model.encode(["human error", "operator error", "verifier error", "system error", "application error"], convert_to_tensor=True)
phrases_list = ["human error", "operator error", "verifier error", "system error", "application error"]
theme_dict = {
    'Colleague Error': ['human error', 'operator error', 'verifier error'],
    'Technical Error': ['system error', 'application error']
}

top_phrases = semantic_search_mpnet(text, phrase_embeddings, phrases_list, theme_dict)
print(top_phrases)