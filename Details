import os
import extract_msg
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize

# Initialize the lemmatizer
lemmatizer = WordNetLemmatizer()

# Define the words/phrases list
word_list = ["example", "test", "document"]

# Convert the list to include both singular and plural forms
def generate_word_forms(word_list):
    word_forms = []
    for word in word_list:
        word_forms.append(word)
        word_forms.append(lemmatizer.lemmatize(word, 'n'))  # singular form
        word_forms.append(lemmatizer.lemmatize(word, 'n') + 's')  # plural form
    return set(word_forms)

word_forms = generate_word_forms(word_list)

# Function to read .msg files and check for word matches
def search_in_msg_file(file_path, word_forms):
    msg = extract_msg.Message(file_path)
    message = msg.body.lower()

    tokens = word_tokenize(message)
    found_words = set(tokens) & word_forms

    if found_words:
        print(f"Matches found in {file_path}: {', '.join(found_words)}")

# Function to traverse directories and subdirectories
def traverse_and_search(root_folder, word_forms):
    for root, dirs, files in os.walk(root_folder):
        for file in files:
            if file.endswith(".msg"):
                file_path = os.path.join(root, file)
                search_in_msg_file(file_path, word_forms)

# Path to the root folder containing .msg files
root_folder = '/path/to/your/folder'

# Traverse the folder and check for matching words
traverse_and_search(root_folder, word_forms)