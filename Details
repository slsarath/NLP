import pandas as pd
import spacy
from sentence_transformers import SentenceTransformer
import umap
import hdbscan
from sklearn.feature_extraction.text import TfidfVectorizer
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import numpy as np

# === Step 1: Load and Group Data ===
df = pd.read_csv("negative_transcripts.csv")  # Replace with your actual file path
df = df[df['Sentiment'] == 'Negative']
grouped = df.groupby('Cust_id')['Transcript'].apply(' '.join).reset_index(name='text')

# === Step 2: Text Preprocessing ===
nlp = spacy.load('en_core_web_sm')

def clean_text(text):
    doc = nlp(text)
    tokens = [token.lemma_.lower() for token in doc if token.is_alpha and not token.is_stop]
    return ' '.join(tokens)

grouped['clean_text'] = grouped['text'].apply(clean_text)

# === Step 3: Sentence Embedding ===
model = SentenceTransformer('all-MiniLM-L6-v2')
embeddings = model.encode(grouped['clean_text'].tolist(), show_progress_bar=True)

# === Step 4: Dimensionality Reduction ===
reducer = umap.UMAP(n_components=10, metric='cosine', random_state=42)
reduced_embeddings = reducer.fit_transform(embeddings)

# === Step 5: Clustering using HDBSCAN ===
clusterer = hdbscan.HDBSCAN(min_cluster_size=5, metric='euclidean', cluster_selection_method='eom')
labels = clusterer.fit_predict(reduced_embeddings)
grouped['theme'] = labels

# === Step 6: Extract Top Keywords per Theme ===
vectorizer = TfidfVectorizer(max_df=0.9, min_df=2)
tfidf = vectorizer.fit_transform(grouped['clean_text'])
terms = vectorizer.get_feature_names_out()

print("\n=== THEME KEYWORDS ===")
for theme in sorted(set(labels)):
    if theme == -1:
        continue
    idxs = np.where(labels == theme)[0]
    theme_tfidf = tfidf[idxs].sum(axis=0)
    scores = np.array(theme_tfidf).flatten()
    top_idxs = scores.argsort()[-5:][::-1]
    keywords = [terms[i] for i in top_idxs]
    print(f"Theme {theme} Keywords: {keywords}")

# === Step 7: Bar Chart of Theme Frequency ===
theme_counts = grouped['theme'].value_counts().sort_index()
plt.figure(figsize=(8, 5))
plt.bar(theme_counts.index.astype(str), theme_counts.values)
plt.xlabel("Theme ID")
plt.ylabel("Number of Customers")
plt.title("Complaint Themes Frequency")
plt.show()

# === Step 8: Word Clouds per Theme ===
for theme in sorted(set(labels)):
    if theme == -1:
        continue
    texts = grouped[grouped['theme'] == theme]['clean_text']
    combined_text = ' '.join(texts)
    wc = WordCloud(width=600, height=300, background_color='white').generate(combined_text)
    plt.figure(figsize=(7, 4))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis('off')
    plt.title(f"Theme {theme} Word Cloud")
    plt.show()